---
title: "Part I — Forecasting with fable"
---

This part of the book covers forecasting with traditional statistical methods. A great book covering these topics in depth is [Forecasting: Principles and Practice](https://otexts.com/fpp3/ "Hyndman Forecasting Book") by Rob Hyndman.

# Time series as tsibbles

**Motivation**

The fable ecosystem is built around the `tsibble` class: a tidy time–series structure with an explicit time index and (optionally) one or more keys. If your data is not in a tsibble, everything else becomes awkward.

```{r}

suppressPackageStartupMessages(library(generics))
suppressPackageStartupMessages(library(tsibble))
require(feasts, quietly = TRUE)
require(fable, quietly = TRUE)
require(fabletools, quietly = TRUE)
require(ggplot2, quietly = TRUE)
require(dplyr, quietly = TRUE)


data <- tsibble(
  date  = as.Date("2020-01-01") + 0:729,
  y     = sin(2*pi*(0:729)/7) + 0.5*sin(2*pi*(0:729)/30.5) + rnorm(730, 0, 0.2), # Sample data with weekly, monthly trends
  index = date
)

data
```

You now have a single daily series with 730 observations.

```{r, fig.cap="Simulated daily series showing weekly seasonality."}
autoplot(data, y) +
  labs(
    title = "Toy demand signal",
    x = "Date",
    y = "y"
  ) + hiplot::theme_isazi(12)
```

Weekly pulses sit on top of a slower monthly undulation—use the plot to confirm the simulated data actually contains the structure you plan to model.

---

# Baseline forecasts: mean, naive, seasonal naive

**Motivation**

Good baselines are essential. Mean, naive, and seasonal–naive are trivial to compute but surprisingly hard to beat on some data. They also give you quick sanity checks.

```{r}
baseline_fc <- data %>%
  model(
    mean   = MEAN(y),
    naive  = NAIVE(y),
    snaive = SNAIVE(y)
  ) %>%
  forecast(h = "30 days")

baseline_fc
```

Each model returns a fable; you can bind, plot, and calculate accuracy with the same tools.

```{r, fig.cap="Thirty–day forecasts from simple baseline models."}
baseline_fc %>%
  autoplot(data) +
  labs(
    title = "Mean, naive, and seasonal naive forecasts",
    x = "Date",
    y = "y"
  ) + hiplot::theme_isazi(12)
```

The naive and seasonal–naive tracks hug the recent history while the simple mean quickly flattens—if even these baselines miss badly, you know the issue sits with the data rather than your fancy model.

```{r}
baseline_metrics <- accuracy(baseline_fc, data)

baseline_metrics %>%
  select(.model, RMSE, MAE, MASE) %>%
  knitr::kable(digits = 3)
```

RMSE highlights absolute scale, MAE is a more robust version, and MASE compares against the seasonal naive (so MASE ≈ 1 means you are matching that baseline). These numbers give you a quick sanity check before trying heavier models.

---

# ARIMA

**Motivation**

ARIMA (and seasonal ARIMA) is still a workhorse model, especially when you want a univariate, interpretable, statistically principled baseline.

```{r}
fit_arima <- data %>%
  model(arima = ARIMA(y))

report(fit_arima)
fit_arima %>% forecast(h = "30 days")
```

```{r, fig.cap="ARIMA forecast with 80% and 95% intervals."}
fit_arima %>%
  forecast(h = "30 days") %>%
  autoplot(data) +
  labs(
    title = "ARIMA vs history",
    x = "Date",
    y = "y"
  ) + hiplot::theme_isazi(12)
```

`ARIMA()` automatically identifies appropriate orders (including seasonal). `report()` gives you parameter estimates and diagnostics.

Check whether the intervals expand meaningfully and that residual autocorrelation (reported by `report()`) is small; otherwise revisit differencing or seasonal order.

---

# ETS (Exponential Smoothing)

**Motivation**

ETS models handle level, trend, and seasonality with explicit error formulations. They are robust and often perform very well on business series.

```{r}
fit_ets <- data %>%
  model(ets = ETS(y))

fit_ets %>% report()
fit_ets %>% forecast(h = "30 days") %>% autoplot(data) +
  labs(
    title = "ETS vs history",
    x = "Date",
    y = "y"
  ) + hiplot::theme_isazi(12)
```

ETS models are often a strong alternative to ARIMA when seasonal patterns are stable and the noise structure is well described by exponential smoothing.

Look for whether ETS captures a smooth mean-reverting seasonal pattern—if the fitted components look jagged the error structure probably needs tweaking.

---

# STL + ETS (decomposition–based forecasting)

**Motivation**

Sometimes you want to separate trend/seasonality from the short–term noise, both for interpretability and modelling flexibility. STL decomposition plus ETS on the seasonally adjusted component is a powerful pattern. 

```{r}
fit_stl <- data %>%
  model(
    stl_ets = decomposition_model(
      STL(y ~ season(window = 7)),
      ETS(season_adjust)
    )
  )

fit_stl %>%
  forecast(h = "30 days") %>% 
  autoplot(data) +
  labs(
    title = "STL/ETS vs history",
    x = "Date",
    y = "y"
  ) + hiplot::theme_isazi(12)
```

Here STL extracts a weekly seasonal component; ETS models the seasonally adjusted series.

```{r, fig.cap="STL decomposition separates trend and weekly seasonality."}
data %>%
  model(stl = STL(y ~ season(window = 7))) %>%
  components() %>%
  autoplot() +
  labs(title = "STL components for the toy series") + 
  hiplot::theme_isazi(12)
```

Focus on whether STL isolates interpretable seasonal components—flat or noisy seasonal panels often mean the period/window choices need adjustment.

---

# Double seasonality

Real world data often has multiple seasonalities. Here's an example with weekly, monthly and annual seasonality:

```{r}
data_seas <- tsibble(
  date  = as.Date("2020-01-01") + 0:729,
  y     = sin(2*pi*(0:729)/7) + 3*sin(2*pi*(0:729)/31) + sin(2*pi*(0:729)/365) + rnorm(730, 0, 0.2), # Sample data with weekly, monthly, yearly trend
  index = date
)
```

You can extend `STL()` with multiple `season()` terms—one per seasonal period—and combine it with your preferred short-term model via `decomposition_model()`. Below, the seasonal components (weekly, monthly, annual) are stripped out and the remainder is forecast either with ETS or ARIMA:

```{r}
fit_multi_stl <- data_seas %>%
  model(
    stl_ets = decomposition_model(
      STL(
        y ~ trend(window = 365) +
          season(period = 7, window = "periodic") +
          season(period = 31, window = "periodic")
      ),
      ETS(season_adjust)
    ),
    stl_arima = decomposition_model(
      STL(
        y ~ trend(window = 365) +
          season(period = 7, window = "periodic") +
          season(period = 31, window = "periodic")
      ),
      ARIMA(season_adjust)
    )
  )
```

```{r, fig.cap="STL handles multiple seasonalities before ETS/ARIMA forecast the deseasonalised series."}
fit_multi_stl %>%
  forecast(h = "90 days") %>%
  autoplot(data_seas) +
  labs(
    title = "Multi-seasonal STL + ETS/ARIMA forecasts",
    x = "Date",
    y = "y"
  )
```

```{r, fig.cap="The STL decomposition explicitly isolates each seasonal component."}
multi_stl_components <- data_seas %>%
  model(
    stl = STL(
      y ~ trend(window = 365) +
        season(period = 7, window = "periodic") +
        season(period = 31, window = "periodic")
    )
  ) %>%
  components()

multi_stl_components %>%
  autoplot() +
  labs(title = "Weekly, monthly, and annual components via STL")
```

All three seasonal panels show smooth oscillations, confirming the multiple-period STL successfully peeled apart the weekly, monthly, and annual effects before modelling the remainder.

# ARIMAX: regression with ARIMA errors

**Motivation**

Most real–world forecasting problems need exogenous drivers: price, promotions, macro variables, events, etc. ARIMAX (regression with ARIMA errors) is the classical tool for this.

```{r}
require(dplyr, quietly = TRUE)

set.seed(42)

data_x <- tsibble(
  date  = as.Date("2020-01-01") + 0:729,
  promo = rbinom(730, 1, 0.15),
  price = runif(730, 9, 12),
  index = date
) %>%
  mutate(
    baseline = sin(2 * pi * (0:729) / 7) + 0.5 * sin(2 * pi * (0:729) / 30.5),
    y = baseline + 1.5 * promo - 0.9 * (price - 10.5) + rnorm(730, 0, 0.2)
  ) %>%
  select(-baseline)

fit_arimax <- data_x %>%
  model(arimax = ARIMA(y ~ promo + price))

report(fit_arimax)

future_x <- tsibble(
  date  = seq.Date(max(data_x$date) + 1, by = "day", length.out = 30),
  promo = 0,
  price = 10.5,
  index = date
)

fit_arimax %>%
  forecast(new_data = future_x)
```

- `promo` captures uplift relative to the baseline.
- The ARIMA error structure accounts for remaining autocorrelation.

You can add more regressors (price, other features) in the same way.

```{r}
tidy(fit_arimax) %>%
  select(term, estimate) %>%
  knitr::kable(digits = 3)
```

The `promo` coefficient is positive (~1.5 units uplift) while the `price` coefficient is negative—both align with how we simulated the impact.

```{r, fig.cap="Promo days lift the fitted baseline relative to non-promo periods."}
fit_arimax %>%
  augment() %>%
  left_join(data_x %>% select(date, promo), by = "date") %>%
  mutate(
    promo_flag = if_else(promo == 1, "Promo", "Non-promo")
  ) %>%
  ggplot(aes(x = date)) +
  geom_line(aes(y = y), colour = "grey70") +
  geom_line(aes(y = .fitted), colour = "#2c7fb8", linewidth = 0.6) +
  geom_point(aes(y = y, colour = promo_flag), alpha = 0.7, size = 1.1) +
  scale_colour_manual(values = c("Promo" = "#d95f02", "Non-promo" = "#1b9e77")) +
  labs(
    title = "Promo uplift relative to fitted baseline",
    x = "Date",
    y = "Sales",
    colour = NULL
  ) +
  hiplot::theme_isazi(12)
```

Promo dots consistently sit above the fitted line, while non-promo points cluster around it—if colours overlap heavily, revisit the regressor definition or consider lagged promo terms.

Prefer classical ARIMAX when you need interpretable coefficients; for ML/global treatments of promotions, see Part II (“Exogenous regressors”) and the dedicated promotions chapter in Part III.

---

# Multiple series with keys

**Motivation**

In retail and operations, you rarely have a single series. You typically have thousands (SKU × store × region). fable’s key semantics let you fit one model per series with identical code.

```{r}
data_multi <- tsibble(
  id   = rep(letters[1:5], each = 730),
  date = rep(as.Date("2020-01-01") + 0:729, 5),
  y    = rnorm(5 * 730),
  key  = id,
  index = date
)

fit_multi <- data_multi %>%
  model(arima = ARIMA(y))

fit_multi %>%
  forecast(h = "30 days")
```

Each key (`id`) gets its own ARIMA model. You can still summarise accuracy and forecasts across all keys.

Use `accuracy(fit_multi)` or `glance()` to spot outlier SKUs where the model struggles—keyed workflows make it straightforward to drill down.

```{r, fig.cap="Visualising a few keyed series makes it obvious when one behaves differently."}
data_multi %>%
  filter(id %in% letters[1:3]) %>%
  autoplot(y) +
  facet_wrap(vars(id), scales = "free_y") +
  labs(
    title = "Sample keyed series (ids a–c)",
    x = "Date",
    y = "y"
  ) +
  hiplot::theme_isazi(12)
```

```{r}
fit_multi %>%
  accuracy() %>%
  select(id, .model, RMSE, MASE) %>%
  knitr::kable(digits = 3)
```

Look for IDs where MASE jumps relative to others—they are prime candidates for bespoke modelling or feature engineering.

---

# Hierarchies & reconciliation (including MinT)

**Motivation**

Hierarchical and grouped time series (e.g. SKU → brand → category → region → country) require *coherent* forecasts: children should add up to parents. Reconciliation methods adjust a set of base forecasts to satisfy aggregation constraints while staying close to the originals.

## Conceptual view

Stack all series at time *t* into a vector **y**ₜ. There exists a summing matrix **S** such that

$$
\mathbf{y}_t = \mathbf{S} \, \mathbf{b}_t
$$

where **b**ₜ are the bottom–level series (e.g., SKUs).  

If you fit arbitrary models to each series, you obtain base forecasts $\hat{\mathbf{y}}_h$ that in general are **not coherent**.

Reconciliation finds adjusted forecasts

$$
\tilde{\mathbf{y}}_h = \mathbf{S} \, \mathbf{P} \, \hat{\mathbf{y}}^{[b]}_h
$$

such that:

- Coherence holds by construction (aggregation uses **S**).
- The adjustments are optimal according to some criterion.

MinT (“Minimum Trace”) chooses **P** to minimise the trace of the reconciled error covariance, using an estimate of the base forecast error covariance matrix **W**.

In one common parameterisation:

$$
\tilde{\mathbf{y}}_h = \mathbf{S} (\mathbf{S}^\top \mathbf{W}^{-1} \mathbf{S})^{-1} \mathbf{S}^\top \mathbf{W}^{-1} \hat{\mathbf{y}}_h
$$

Intuition:

- Series with **high variance** forecasts get shrunk more towards coherent aggregates.
- Series whose **errors are highly correlated** with others share information more strongly.

In practice, fable estimates **W** from in–sample residuals and performs this matrix algebra for you.

## Using reconciliation in fable

```{r}
require(fabletools, quietly = TRUE)
require(tsibbledata, quietly = TRUE)

tourism <- tourism  # key = (Region, Purpose)
tourism_small <- tourism %>%
  filter(
    Region %in% c("Sydney", "Melbourne", "Brisbane", "Perth"),
    Purpose %in% c("Business", "Holiday")
  )

fit <- tourism_small %>%
  model(ets = ETS(Trips))

rec <- fit %>%
  reconcile(
    bu = bottom_up(ets)
  )

fc <- rec %>%
  forecast(h = "3 years")
```

Guidelines:

- **bottom_up()**: use when bottom–level series are well measured and you care most about them.
- **min_trace() / mint_shrink**: use when you want balanced accuracy across levels, and when noise at the bottom is substantial.
- (Omitted from the runnable example for speed, but you can add `min_trace(ets)` or `min_trace(ets, method = "mint_shrink")` in the `reconcile()` call above to try MinT.)

```{r, fig.cap="Reconciled forecasts for Sydney holiday travel across reconciliation strategies."}
fc %>%
  filter(Region == "Sydney", Purpose == "Holiday") %>%
  autoplot(
    tourism_small %>%
      filter(Region == "Sydney", Purpose == "Holiday")
  ) +
  labs(
    title = "Sydney holiday forecasts: base ETS vs bottom-up",
    x = "Year",
    y = "Trips"
  ) + 
  hiplot::theme_isazi(12)
```

Bottom-up coherence forces the reconciled line (orange) to track the aggregate closely; if the adjustment is too aggressive, try MinT with shrinkage to balance bottom vs top accuracy.

---

# Rolling–origin evaluation (tscv)

**Motivation**

A single train/test split can be misleading in time series. Rolling–origin (or “time series cross–validation”) repeatedly trains on expanding windows and evaluates a fixed horizon ahead.

```{r}
cv <- data %>%
  stretch_tsibble(.init = 365, .step = 30)

cv_results <- cv %>%
  model(arima = ARIMA(y)) %>%
  forecast(h = 30)

cv_plot <- cv_results %>%
  filter(.model == "arima") %>%
  as_tibble() %>%
  mutate(window = factor(.id)) %>%
  ggplot(aes(x = date, y = .mean, colour = window, group = window)) +
  geom_line(alpha = 0.7) +
  geom_line(
    data = as_tibble(data),
    aes(x = date, y = y),
    inherit.aes = FALSE,
    colour = "black",
    linewidth = 0.4
  ) +
  labs(
    title = "Rolling-origin evaluation windows",
    subtitle = "Coloured lines = individual origins; black = full history",
    x = "Date",
    y = "Forecast"
  ) +
  guides(colour = "none")

cv_accuracy <- accuracy(cv_results, data)
```

```{r, fig.cap="Expanding windows ensure every 30-day holdout is evaluated in order."}
cv_plot + hiplot::theme_isazi(12)
```

Each row of the stretched tsibble represents one training window; `forecast(h = 30)` produces 30–day–ahead forecasts for that window.

```{r}
cv_accuracy %>%
  select(.model, .type, RMSE, MAE, MASE) %>%
  knitr::kable(digits = 3)
```

MASE close to 1 signals parity with the in-sample seasonal naive—if it balloons across origins, increase the initial window or revisit your preprocessing.

---

# Combining forecasts

**Motivation**

Forecast combinations are cheap and often yield gains over any single model. Even simple averages can be very effective.

```{r}
fit <- data %>%
  model(
    arima = ARIMA(y),
    ets   = ETS(y),
    mean  = MEAN(y)
  )

combo <- fit %>%
  mutate(
    combo = (arima + ets + mean) / 3
  )

combo %>%
  forecast(h = "30 days")
```

You can also use regression–based combinations or more sophisticated weighting schemes via `regress_combination()` in fabletools.

Averaging typically shrinks extremes and stabilises intervals; check whether the combined trajectory reduces variance relative to the single-model paths before investing in more elaborate stacking.
