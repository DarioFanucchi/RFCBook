---
title: "Part III — Extensions, retail patterns & feature engineering"
---

# Advanced timetk usage

**Motivation**

`timetk` is a powerful toolkit for time–based feature engineering, visualisation, and cross–validation. It plays very nicely with both tidymodels and direct data–frame workflows.

## Time series signatures

You can generate time–based features directly, without recipes:

```{r}
require(dplyr, quietly = TRUE)
time_series_split <- timetk::time_series_split
time_series_cv <- timetk::time_series_cv

xgb_spec <- parsnip::boost_tree(
  trees = 1000,
  learn_rate = 0.03,
  tree_depth = 8
) %>%
  parsnip::set_engine("xgboost") %>%
  parsnip::set_mode("regression")

data <- tibble::tibble(
  date = as.Date("2020-01-01") + 0:729,
  y    = sin(2*pi*(0:729)/7) + rnorm(730, 0, 0.2)
)

rec <- recipes::recipe(y ~ date, data = data)

data_sig <- data %>%
  timetk::tk_augment_timeseries_signature(date) %>%
  select(-tidyselect::contains("hour"), -tidyselect::contains("minute"),
         -tidyselect::contains("second"), -tidyselect::contains("am.pm"))
```

This yields fields like year, month, week, day of week, quarter, etc.

## Lags and sliding windows

```{r}
data_lags <- data_sig %>%
  timetk::tk_augment_lags(y, .lags = c(1, 7, 14))

data_roll <- data_lags %>%
  timetk::tk_augment_slidify(
    .value  = y,
    .f      = ~ mean(.x, na.rm = TRUE),
    .period = 7,
    .align  = "right",
    .partial = FALSE,
    .names  = "roll_mean_7"
  )
```

This produces lagged versions of `y` and a rolling 7–day mean.

## Visualising time–series CV plans

```{r}
cv_plan <- time_series_cv(
  data,
  assess     = 90,
  skip       = 30,
  cumulative = TRUE
)

cv_plan %>%
  timetk::tk_time_series_cv_plan() %>%
  timetk::plot_time_series_cv_plan(
    .date_var = date,
    .value    = y
  )
```

This allows you to inspect your rolling window splits visually and confirm they make sense.

---

# Promotions, price & cannibalisation

**Motivation**

In retail, static seasonality is the easy part. The interesting dynamics come from promotions, pricing, and interactions across products (cannibalisation). We look at classical (fable) and ML (modeltime) approaches.

## ARIMAX in fable for promo & price

```{r}
data_retail <- tsibble::tsibble(
  date   = as.Date("2020-01-01") + 0:729,
  sales  = rpois(730, 100),
  promo  = rbinom(730, 1, 0.1),
  price  = runif(730, 9, 12),
  index  = date
)

fit_arimax <- data_retail %>%
  fabletools::model(
    arimax = fable::ARIMA(sales ~ promo + price)
  )

fit_arimax %>% fabletools::report()
```

Interpretation:

- Coefficient on `promo` ≈ average incremental units during promo.
- Coefficient on `price` ≈ price elasticity (units per price unit); often negative.

You can add lags and interactions, e.g. `promo + lag(promo) + price + promo:holiday_flag`.

## ML global model for promos & price

```{r}
data_panel <- tibble(
  sku   = rep(letters[1:20], each = 730),
  date  = rep(as.Date("2020-01-01") + 0:729, 20),
  sales = rpois(20 * 730, 100),
  promo = rbinom(20 * 730, 1, 0.1),
  price = runif(20 * 730, 9, 12)
) %>%
  arrange(date, sku)

splits_p <- time_series_split(
  data_panel,
  assess     = 90,
  cumulative = TRUE
)

rec_promos <- recipes::recipe(sales ~ sku + date + promo + price,
                     data = rsample::training(splits_p)) %>%
  timetk::step_timeseries_signature(date) %>%
  recipes::step_rm(date) %>%
  recipes::step_dummy(recipes::all_nominal_predictors(), one_hot = TRUE) %>%
  recipes::step_zv(recipes::all_predictors()) %>%
  recipes::step_normalize(recipes::all_numeric_predictors())

wf_promos <- workflows::workflow() %>%
  workflows::add_recipe(rec_promos) %>%
  workflows::add_model(xgb_spec)

fit_promos <- workflows::fit(wf_promos, rsample::training(splits_p))
```

For cannibalisation, you precompute features such as:

- `category_sales_ex_sku`
- `brand_sales`
- `competitor_price`

via group–by / lag operations, then feed into the recipe.

---

# Feature engineering cookbook for ML time series

**Motivation**

Global ML models live or die on features. This chapter summarises common patterns you can compose.

## Time–based features

- `step_timeseries_signature(date)` or `tk_augment_timeseries_signature()`.
- Fourier terms for long seasonalities (e.g. yearly with daily data).

## Lags & rolling statistics

In recipes:

```{r}
rec_lags <- rec %>%
  recipes::step_lag(y, lag = c(1, 7, 14)) %>%
  timetk::step_slidify(
    y,
    period = 7,
    .f = mean,
    align = "right",
    partial = FALSE,
    names = "roll_mean_7"
  ) %>%
  timetk::step_slidify(
    y,
    period = 7,
    .f = sd,
    align = "right",
    partial = FALSE,
    names = "roll_sd_7"
  )
```

These capture local dynamics that trees exploit well.

## Calendar & holiday features

Use `step_holiday()` or precomputed holiday tables to add dummies for important days, long weekends, etc.

## Price & promo–derived features

Examples:

- `discount_pct = pmax(0, (list_price - price) / list_price)`
- `promo_flag = as.integer(discount_pct > 0.1)`
- `price_index` vs category average.

## Cross–series interaction features

Use group–by / summarise to compute, for each date and category:

- `category_sales`  
- `category_sales_ex_sku`  
- `top_brand_share`  

Then join back to the main table and feed into your recipe.

---

# Per–SKU vs global models

**Motivation**

A key design choice: do you fit a separate model per SKU (e.g., ARIMA in fable) or a global model (e.g., XGBoost in modeltime)? It’s worth comparing them quantitatively.

## Per–SKU ARIMA (fable)

```{r}
ts_panel <- tsibble::as_tsibble(
  data_panel,
  key   = sku,
  index = date
)

split_date <- as.Date("2021-06-30")

train_ts <- ts_panel %>%
  filter(date <= split_date)

test_ts <- ts_panel %>%
  filter(date > split_date)

fit_per <- train_ts %>%
  fabletools::model(arima = fable::ARIMA(sales))

acc_per <- fc_per <- fit_per %>%
  fabletools::forecast(h = dplyr::n_distinct(test_ts$date)) %>%
  as_tibble() %>%
  transmute(
    sku,
    date,
    .pred = purrr::map_dbl(sales, mean)
  ) %>%
  left_join(
    tsibble::as_tibble(test_ts) %>%
      select(sku, date, sales),
    by = c("sku", "date")
  ) %>%
  group_by(sku) %>%
  summarise(
    rmse_per = yardstick::rmse_vec(truth = sales, estimate = .pred),
    .groups = "drop"
  )
```

## Global XGBoost (modeltime)

```{r}
splits_panel <- time_series_split(
  data_panel,
  assess     = 600,
  cumulative = TRUE
)

rec_global <- recipes::recipe(sales ~ sku + date + promo + price,
                     data = rsample::training(splits_panel)) %>%
  timetk::step_timeseries_signature(date) %>%
  recipes::step_rm(date) %>%
  recipes::step_dummy(recipes::all_nominal_predictors(), one_hot = TRUE) %>%
  recipes::step_zv(recipes::all_predictors()) %>%
  recipes::step_normalize(recipes::all_numeric_predictors())

wf_global <- workflows::workflow() %>%
  workflows::add_recipe(rec_global) %>%
  workflows::add_model(xgb_spec)

fit_global <- workflows::fit(wf_global, rsample::training(splits_panel))

fc_global <- modeltime::modeltime_table(fit_global) %>%
  modeltime::modeltime_calibrate(rsample::testing(splits_panel)) %>%
  modeltime::modeltime_forecast(
    new_data    = rsample::testing(splits_panel),
    actual_data = data_panel,
    keep_data   = TRUE
  )
```

Map to per–SKU RMSE:

```{r}
acc_global <- fc_global %>%
  filter(.key == "prediction") %>%
  group_by(sku) %>%
  summarise(
    rmse_global = yardstick::rmse_vec(truth = sales, estimate = .value),
    .groups = "drop"
  )

comparison <- acc_per %>%
  left_join(acc_global, by = "sku") %>%
  mutate(diff = rmse_per - rmse_global)
```

You can now see how many SKUs prefer global vs per–SKU models and by how much.

---

# End–to–end engine pattern

**Motivation**

In production you want a repeatable pipeline: ingest data, build features, train models, backtest, and store configuration for deployment.

A minimal pattern:

1. **Process tables** (facts + dimensions).
2. **Feature builder** function.
3. **Modelling** function(s) (fable and/or modeltime).
4. **Backtest harness** (loop over cutoff dates).
5. **Model registry** (chosen config per segment).

Pseudocode for modelling step:

```{r}
fit_forecast_models <- function(features, horizon, engine = c("fable", "modeltime")) {
  engine <- match.arg(engine)
  if (engine == "fable") {
    ts <- features %>%
      tsibble::as_tsibble(key = c(sku, depot), index = date)

    ts %>% fabletools::model(fable::ARIMA(qty))
  } else {
    splits <- time_series_split(features, assess = horizon, cumulative = TRUE)

    rec <- recipes::recipe(qty ~ ., data = rsample::training(splits)) %>%
      timetk::step_timeseries_signature(date) %>%
      recipes::step_rm(date) %>%
      recipes::step_dummy(recipes::all_nominal_predictors()) %>%
      recipes::step_zv(recipes::all_predictors()) %>%
      recipes::step_normalize(recipes::all_numeric_predictors())

    wf <- workflows::workflow() %>%
      workflows::add_recipe(rec) %>%
      workflows::add_model(xgb_spec)

    workflows::fit(wf, rsample::training(splits))
  }
}
```

You then wrap this in backtesting and orchestration appropriate to your environment (e.g., cron, Airflow, Hudson–style process orchestrator).
